{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# real EDA\n",
        "  > pls use r environment\n",
        "  > do: conda activate r\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!conda env list\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## general import and setup\n",
        "\n",
        "The `R` interfaces can be disabled if not needed.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd;\n",
        "import numpy as np;\n",
        "from matplotlib import pyplot as plt;\n",
        "from matplotlib import dates as mdates;\n",
        "import seaborn as sns;\n",
        "\n",
        "sns.set_context(\"notebook\", font_scale=1.5)\n",
        "# R interfaces, can be disabled if not needed\n",
        "# import rpy2;\n",
        "# %load_ext rpy2.ipython\n",
        "#\n",
        "# import rpy2.robjects as ro;\n",
        "#\n",
        "# from rpy2.robjects import pandas2ri;\n",
        "# from rpy2.robjects import default_converter\n",
        "# from rpy2.robjects.conversion import localconverter;\n",
        "#\n",
        "# from rpy2.robjects.packages import importr;\n",
        "#\n",
        "# utils = importr(\"utils\");\n",
        "# grdevices = importr('grDevices');\n",
        "# infenergy = importr('infenergy');\n",
        "#\n",
        "#\n",
        "# def help_r( python_name ):\n",
        "#     print( str( utils.help( python_name.replace('_','.') ) ) );\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# main EDA\n",
        "\n",
        "remember ipykernel can do basic shell like `cd`, `ls`, etc\n",
        "as long as you append `!` before it.\n",
        "\n",
        "e.g.\n",
        "  - `!echo test`,\n",
        "  - `!echo {data} | grep -E '\\d+:\\d+:'`\n",
        "\n",
        "note that {data} is a python variable\n",
        "\n",
        "Also magic commands equilivant of them via appending `%`\n",
        "\n",
        "_note that this is fine if automagic is enabled but must add `%` if running block_\n",
        "\n",
        "e.g.\n",
        " - %pwd\n",
        " - pwd ../misc\n",
        " - %R example(get.inf.meter.data)\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "combined_data_with_nans = pd.read_csv('/Users/lautinyeung/Desktop/work/DS MSc/THESIS/code/data/preprocessed/combined/combined_data_with_nans.csv', index_col='OB_TIME')\n",
        "combined_data_with_nans.index = pd.to_datetime(combined_data_with_nans.index).tz_convert(tz='GMT')\n",
        "\n",
        "combined_data_with_nans.info()\n",
        "combined_data_with_nans.head()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "ax = sns.heatmap(\n",
        "    combined_data_with_nans.dropna().corr(),\n",
        "    cmap=plt.cm.coolwarm,\n",
        "    vmax=1.0,\n",
        "    linewidths=0.1,\n",
        "    linecolor='white',\n",
        "    square=True,\n",
        "    annot=True,\n",
        "    annot_kws={\"size\": 10}\n",
        ")\n",
        "\n",
        "# hided, too messy.  basically the heatmap but with kde of each feature + points projected into each 2d dimension\n",
        "# pp = sns.pairplot(combined_data_with_nans.dropna(),\n",
        "#                   height=1.8, aspect=1.2,\n",
        "#                   plot_kws=dict(edgecolor=\"k\", linewidth=0.5),\n",
        "#                   diag_kws=dict(shade=True), # \"diag\" adjusts/tunes the diagonal plots\n",
        "#                   diag_kind=\"kde\") # use \"kde\" for diagonal plots\n",
        "#\n",
        "#\n",
        "# combined_data_with_nans['WIND_DIRECTION'].plot(kind='kde')\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## removed\n",
        "Parrallel coordinates is not common and not intuitive to interpret for majority of readers\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "#\n",
        "# ss = StandardScaler()\n",
        "# combined_data_with_nans_scaled = ss.fit_transform(combined_data_with_nans)\n",
        "# combined_data_with_nans_scaled = pd.DataFrame(combined_data_with_nans_scaled, columns=combined_data_with_nans.columns)\n",
        "# combined_data_with_nans_scaled.index = combined_data_with_nans.index\n",
        "# combined_data_with_nans_scaled.head()\n",
        "#\n",
        "#\n",
        "# "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " "
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# from pandas.plotting import parallel_coordinates\n",
        "#\n",
        "# fig = plt.figure(figsize=(20, 8))\n",
        "# title = fig.suptitle(\"Parallel Coordinates\", fontsize=18)\n",
        "# fig.subplots_adjust(top=0.93, wspace=0)\n",
        "#\n",
        "#\n",
        "# pc = parallel_coordinates(combined_data_with_nans_scaled.dropna().assign(dummy_class='dummy_class'),\n",
        "#                           'dummy_class')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "rip\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(3, 2, figsize=(15,15))\n",
        "\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014-4-30':'2015-4-30'].plot(ax=axs[0,0])\n",
        "axs[0,0].set_title('1 year')\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014-4-30':'2014-11-20'].plot(ax=axs[0,1])\n",
        "axs[0,1].set_title('6 months')\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014-4-30':'2014-7-29'].plot(ax=axs[1,0])\n",
        "axs[1,0].set_title('3 months quarter')\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014-4-30':'2014-5-13'].plot(ax=axs[1,1])\n",
        "axs[1,1].set_title('2 weeks')\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014-4-30':'2014-4-30'].plot(ax=axs[2,0])\n",
        "axs[2,0].set_title('1 day')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resampling daily and weekly\n",
        "bin_kwh are diffs, resample should go by sum:\n",
        "sum( diffs )\n",
        "\n",
        "= c<sub>n</sub> - c<sub>n-1</sub> + c<sub>n-1</sub> - c<sub>n-2</sub> .... c<sub>3</sub> - c<sub>2</sub> + c<sub>2</sub> - c<sub>1</sub>\n",
        "\n",
        "= c<sub>n</sub> - c<sub>1</sub>\n",
        "\n",
        "Weather feature are most useful to average.\n",
        "Taking last or max wont work.\n",
        "\n",
        "Note for feature type while averaging, default to mean except:\n",
        "\n",
        "WMO_HR_SUN_DUR: hours of sunlight duration within that hour.  USE SUM.\n",
        "\n",
        "[WIND_SPEED, WIND_DIRECTION]: self-explainatory.  USE SPECIAL MEAN ref. research_gate_avg_wind\n",
        "\n",
        "PRCP_AMT: self-explainatory. recorded hourly in mm.  USE SUM.\n",
        "\n",
        "OTHER:\n",
        "CLD_BASE_HT: height of clouds, maybe unreliably recorded.  Data seems rounded but unclear.\n",
        "Taking means seems to change the distribution a lot, doesnt quite match.  Logically this should be MEANed."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "combined_data_with_nans['AIR_TEMPERATURE'][combined_data_with_nans.isna()['AIR_TEMPERATURE']]\n",
        "\n",
        "\n",
        "\n",
        "cols_to_sum  = np.array(['bin_kwh', 'WMO_HR_SUN_DUR', 'DRV_HR_SUN_DUR','PRCP_AMT'])\n",
        "cols_winds   = np.array(['WIND_SPEED', 'WIND_DIRECTION'])\n",
        "cols_to_mean = np.array([ col for col in combined_data_with_nans.columns if col not in np.append(cols_to_sum, cols_winds)])\n",
        "\n",
        "len(   np.append(np.append(cols_to_sum, cols_winds), cols_to_mean)   )\n",
        "len( combined_data_with_nans.columns )\n",
        "\n",
        "part_mean = combined_data_with_nans[ cols_to_mean ].resample('D').mean();\n",
        "part_mean.shape\n",
        "\n",
        "part_sum = combined_data_with_nans[ cols_to_sum ].resample('D').sum()\n",
        "part_sum.shape\n",
        "\n",
        "#see ref. research_gate_avg_wind\n",
        "def to_wind_avg( data ):\n",
        "    sp = data['WIND_SPEED'];\n",
        "    dir = data['WIND_DIRECTION'];\n",
        "\n",
        "    u = -sp * np.sin( np.pi * dir / 180 )\n",
        "    v = -sp * np.cos( np.pi * dir / 180 )\n",
        "\n",
        "    mean_u = np.mean(u);\n",
        "    mean_v = np.mean(v);\n",
        "\n",
        "    flow = lambda deg: 180 if deg < 180 else -180;\n",
        "\n",
        "    mean_sp  = ( mean_u**2 + mean_v**2 ) ** 0.5\n",
        "    arctans_deg  = np.arctan2( mean_u, mean_v ) * 180 / np.pi\n",
        "    mean_dir = arctans_deg + flow(arctans_deg);\n",
        "\n",
        "    return pd.Series([mean_sp, mean_dir], index=['WIND_SPEED','WIND_DIRECTION'])\n",
        "\n",
        "part_winds = combined_data_with_nans[ cols_winds ].groupby( pd.Grouper(freq='1d') ).apply( to_wind_avg )\n",
        "part_winds.shape\n",
        "\n",
        "combined_data_with_nans_daily = pd.concat([part_mean, part_sum, part_winds], axis=1)\n",
        "combined_data_with_nans_daily = combined_data_with_nans_daily[ combined_data_with_nans.columns ] #unify column ordering\n",
        "combined_data_with_nans_daily.shape\n",
        "\n",
        "combined_data_with_nans_daily.isna()['bin_kwh'].value_counts()\n",
        "\n",
        "combined_data_with_nans_daily.head()\n",
        "\n",
        "# recording at first day started out at 18:00, drop this day for daily\n",
        "combined_data_with_nans_daily = combined_data_with_nans_daily.iloc[1:]\n",
        "\n",
        "combined_data_with_nans_daily.head()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "part_mean = combined_data_with_nans[ cols_to_mean ].resample('W').mean();\n",
        "part_mean.shape\n",
        "\n",
        "part_sum = combined_data_with_nans[ cols_to_sum ].resample('W').sum()\n",
        "part_sum.shape\n",
        "\n",
        "part_winds = combined_data_with_nans[ cols_winds ].groupby( pd.Grouper(freq='1w') ).apply( to_wind_avg )\n",
        "part_winds.shape\n",
        "\n",
        "combined_data_with_nans_weekly = pd.concat([part_mean, part_sum, part_winds], axis=1)\n",
        "combined_data_with_nans_weekly = combined_data_with_nans_weekly[ combined_data_with_nans.columns ] #unify column ordering\n",
        "combined_data_with_nans_weekly.shape\n",
        "\n",
        "combined_data_with_nans_weekly.isna()['bin_kwh'].value_counts()\n",
        "\n",
        "combined_data_with_nans_weekly.head()\n",
        "\n",
        "# recording at first day started out at 18:00, still significant at weekly, drop first week for weekly\n",
        "combined_data_with_nans_weekly = combined_data_with_nans_weekly.iloc[1:]\n",
        "\n",
        "combined_data_with_nans_weekly.head()\n",
        "\n",
        "combined_data_with_nans.shape\n",
        "combined_data_with_nans_daily.shape\n",
        "combined_data_with_nans_weekly.shape\n",
        "\n",
        "combined_data_with_nans_weekly.index.to_series().dt.dayofweek\n",
        "\n",
        "\n",
        "sns.kdeplot(data=combined_data_with_nans['CLD_BASE_HT']['2015-1'], bw=10)\n",
        "sns.kdeplot(data=combined_data_with_nans_daily['CLD_BASE_HT']['2015-1'], bw=6)\n",
        "combined_data_with_nans['CLD_BASE_HT'].value_counts()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labels\n",
        "holiday:\n",
        " - hourly\n",
        " - daily\n",
        " - weekly\n",
        "\n",
        "weekday / weekend:\n",
        " - hourly\n",
        " - daily\n",
        "\n",
        "no wind:\n",
        " - hourly\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#no wind label\n",
        "no_wind_mask = np.logical_and(combined_data_with_nans.WIND_SPEED == 0, combined_data_with_nans.WIND_DIRECTION == 0);\n",
        "\n",
        "new_combined_data_with_nans = combined_data_with_nans[ no_wind_mask ].assign( NO_WIND=1 ).append( combined_data_with_nans[ np.logical_not( no_wind_mask ) ].assign( NO_WIND=0 )  ).sort_index()\n",
        "\n",
        "combined_data_with_nans.equals( new_combined_data_with_nans.iloc[:,:-1] )\n",
        "\n",
        "new_combined_data_with_nans\n",
        "\n",
        "#weekend label\n",
        "def is_weekend( dayofweek ):\n",
        "    return 1 if dayofweek >= 5 else 0;\n",
        "\n",
        "# 2 – 25 Aug 2013\n",
        "# https://www.bbc.co.uk/events/rgjc6q/by/date/2013\n",
        "fringe13 = pd.date_range('2013-08-02 00:00','2013-08-25 23:00', freq='H', tz='GMT')\n",
        "\n",
        "# 1 – 24 Aug 2014\n",
        "# https://www.bbc.co.uk/events/rgjc6q/by/date/2014\n",
        "fringe14 = pd.date_range('2014-08-01 00:00','2014-08-24 23:00', freq='H', tz='GMT')\n",
        "\n",
        "# 4 – 26 Aug 2015\n",
        "# https://www.bbc.co.uk/events/rgjc6q/by/date/2015\n",
        "fringe15 = pd.date_range('2015-08-04 00:00','2015-08-26 23:00', freq='H', tz='GMT')\n",
        "\n",
        "def is_fringe( timestamp ):\n",
        "    return 1 if ( timestamp in fringe13 or timestamp in fringe14 or timestamp in fringe15 ) else 0;\n",
        "\n",
        "\n",
        "# 24-31 December 2013\tUniversity closed\n",
        "# 1-2 January 2014\tUniversity closed\n",
        "# https://www.ed.ac.uk/semester-dates/201314\n",
        "winter_closure1314 = pd.date_range('2013-12-24 00:00','2014-01-02 23:00', freq='H', tz='GMT')\n",
        "\n",
        "# 24-31 December 2014\tUniversity closed\n",
        "# 1-2 January 2015\tUniversity closed\n",
        "# https://www.ed.ac.uk/semester-dates/201415\n",
        "winter_closure1415 = pd.date_range('2014-12-24 00:00','2015-01-02 23:00', freq='H', tz='GMT')\n",
        "\n",
        "# 24 December 2015 - 4 January 2016\tUniversity closed\n",
        "# https://www.ed.ac.uk/semester-dates/201516\n",
        "winter_closure1516 = pd.date_range('2015-12-24 00:00','2016-01-04 23:00', freq='H', tz='GMT')\n",
        "\n",
        "def is_winter_closure( timestamp ):\n",
        "    return 1 if ( timestamp in winter_closure1314 or timestamp in winter_closure1415 or timestamp in winter_closure1516 ) else 0;\n",
        "\n",
        "new_combined_data_with_nans = new_combined_data_with_nans.assign(\n",
        "        WEEKEND=new_combined_data_with_nans.index.to_series().dt.dayofweek.map( is_weekend ).to_numpy(),\n",
        "        FRINGE=new_combined_data_with_nans.index.to_series().map( is_fringe ).to_numpy(),\n",
        "        WINTER_CLOSURE=new_combined_data_with_nans.index.to_series().map( is_winter_closure ).to_numpy()\n",
        "    )\n",
        "\n",
        "new_combined_data_with_nans_daily = combined_data_with_nans_daily.assign(\n",
        "        WEEKEND=combined_data_with_nans_daily.index.to_series().dt.dayofweek.map( is_weekend ).to_numpy(),\n",
        "        FRINGE=combined_data_with_nans_daily.index.to_series().map( is_fringe ).to_numpy(),\n",
        "        WINTER_CLOSURE=combined_data_with_nans_daily.index.to_series().map( is_winter_closure ).to_numpy()\n",
        "    )\n",
        "\n",
        "\n",
        "\n",
        "#holiday label\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from windrose import WindroseAxes;\n",
        "\n",
        "combined_data_with_nans['WIND_SPEED'].describe()\n",
        "\n",
        "fig=plt.figure( figsize=(10,15) )\n",
        "ax = fig.add_subplot(2, 2, 1, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( combined_data_with_nans['WIND_DIRECTION'], combined_data_with_nans['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 2, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( combined_data_with_nans_daily['WIND_DIRECTION'], combined_data_with_nans_daily['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 3, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( combined_data_with_nans_weekly['WIND_DIRECTION'], combined_data_with_nans_weekly['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "\n",
        "fig.legend(labels=['0.0 - 8.0','8.0 - 16.0','16.0 - 24.0', '24.0 - 32.0', '32.0 - infinity'],   # The labels for each line\n",
        "           loc=\"center\",   # Position of legend\n",
        "           borderaxespad=0.1,    # Small spacing around legend box\n",
        "           title=\"Wind Speed Colour Guide\"  # Title for the legend\n",
        "           )\n",
        "\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_data_with_nans_weekly['2016'].index.to_series().dt.weekofyear\n",
        "from matplotlib.dates import DateFormatter;\n",
        "\n",
        "\n",
        "foobar = combined_data_with_nans_weekly['2013'];\n",
        "foobar.index = combined_data_with_nans_weekly['2013'].index.to_series().dt.weekofyear.to_numpy()\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = combined_data_with_nans_weekly[ year ];\n",
        "    temp.index = combined_data_with_nans_weekly[ year ].index.to_series().dt.weekofyear.to_numpy()\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "foobar = foobar.rename( columns={'index':'weekofyear'})\n",
        "\n",
        "#with sns.axes_style(\"whitegrid\"):\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.lineplot( data=foobar, x='weekofyear', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "#ax.set_title('Annual bin_kwh 2013-2020 (weekly)')\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "ax.set_xticks(np.arange(1,53,4+1/3))\n",
        "ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "ax.set(ylim=(0,50000))\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar, x='weekofyear', y='bin_kwh', hue='year', legend='full')\n",
        "    #   ax.set_title('Annual bin_kwh 2013-2020 (weekly)')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks(np.arange(1,53,4+1/3))\n",
        "    ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "    ax.set(ylim=(0,50000))\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "foobar = combined_data_with_nans_daily['2013'];\n",
        "foobar.index = pd.to_datetime( combined_data_with_nans_daily['2013'].index.strftime('%m-%d-00') )\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = combined_data_with_nans_daily[ year ];\n",
        "    temp.index = pd.to_datetime( combined_data_with_nans_daily[ year ].index.strftime('%m-%d-00') )\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.lineplot( data=foobar, x='OB_TIME', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "ax.xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "ax.set_title('Annual bin_kwh 2013-2020 (daily)')\n",
        "ax.set_xlabel('Month')\n",
        "ax.set_xticks(pd.date_range('2000-01-01','2000-12-31', freq='MS'))\n",
        "ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
        "sns.lineplot( data=combined_data_with_nans_daily['2014-03':'2014-05']['bin_kwh'], err_style='band', ci='sd', ax=axs[0])\n",
        "axs[0].set_xlabel('Month')\n",
        "axs[0].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[0].set_xticks(pd.date_range('2014-03-01','2014-05-31', freq='MS'))\n",
        "axs[0].set_xticklabels([\"Mar\",'Apr','May'])\n",
        "axs[0].set(ylim=(0, 7500))\n",
        "sns.lineplot( data=combined_data_with_nans_daily['2018-03':'2018-05']['bin_kwh'], err_style='band', ci='sd', ax=axs[1])\n",
        "axs[1].set_xlabel('Month')\n",
        "axs[1].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[1].set_xticks(pd.date_range('2018-03-01','2018-05-31', freq='MS'))\n",
        "axs[1].set_xticklabels([\"Mar\",'Apr','May'])\n",
        "axs[1].set(ylim=(0, 7500))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "spring_mask = np.logical_and( foobar['OB_TIME'] >= '2000-03-01', foobar['OB_TIME'] <= '2000-05-31')\n",
        "\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar[spring_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci='sd')\n",
        "    ax.xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    #ax.set_title('Spring (Mar - May) bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks(pd.date_range('2000-03-01','2000-05-31', freq='MS'))\n",
        "    ax.set_xticklabels([\"Mar\",'Apr','May'])\n",
        "    ax.set(ylim=(2500, 7000))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "summer_mask = np.logical_and( foobar['OB_TIME'] >= '2000-06-01', foobar['OB_TIME'] <= '2000-08-31')\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar[summer_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax.xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    #ax.set_title('Summer (June - August) bin_kwh 2013-2019')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks(pd.date_range('2000-6','2000-08-31', freq='MS'))\n",
        "    ax.set_xticklabels([\"Jun\",'Jul','Aug'])\n",
        "    ax.set(ylim=(2500, 7000))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "autumn_mask = np.logical_and( foobar['OB_TIME'] >= '2000-09-01', foobar['OB_TIME'] <= '2000-11-30')\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar[autumn_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax.xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    #ax.set_title('Autumn (September - November) bin_kwh 2013-2019')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks(pd.date_range('2000-9','2000-11-30', freq='MS'))\n",
        "    ax.set_xticklabels([\"Sep\",'Oct','Nov'])\n",
        "    ax.set(ylim=(2500, 7000))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "foobar = combined_data_with_nans_daily['2013-12-01':'2014-2'];\n",
        "foobar.index = np.arange( len( combined_data_with_nans_daily['2013-12-01':'2014-2'].index ) )\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
        "    temp = combined_data_with_nans_daily[ str(year)+'-12-01': str(year+1)+'-2'];\n",
        "    temp.index = np.arange( len( combined_data_with_nans_daily[str(year)+'-12-01': str(year+1)+'-2'].index ) )\n",
        "    temp = temp.assign( year=str(year) )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "foobar = foobar.rename(columns={'index':'day'})\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar, x='day', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax.xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    #ax.set_title('Winter (December - Feburary) bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_yticks( np.arange(2500, 7500, 500) )\n",
        "    ax.set_xticks( np.arange(0,91,30) )\n",
        "    ax.set_xticklabels([\"Dec\",'Jan','Feb'])\n",
        "    ax.set(ylim=(2500, 7000))\n",
        "#    plt.savefig('/Users/lautinyeung/Desktop/foo.pdf',\n",
        "#            dpi=300,\n",
        "#            orientation='portrait',\n",
        "#            bbox_inches='tight', pad_inches=0)\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "foobar = combined_data_with_nans_daily['2013'];\n",
        "foobar.index = pd.to_datetime( combined_data_with_nans_daily['2013'].index.strftime('%m-%d-00') )\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = combined_data_with_nans_daily[ year ];\n",
        "    temp.index = pd.to_datetime( combined_data_with_nans_daily[ year ].index.strftime('%m-%d-00') )\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
        "    spring_mask = np.logical_and( foobar['OB_TIME'] >= '2000-03-01', foobar['OB_TIME'] <= '2000-05-31')\n",
        "\n",
        "    plt.figure(figsize=(15,8))\n",
        "    axs[0,0] = sns.lineplot( ax=axs[0,0], data=foobar[spring_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci='sd')\n",
        "    axs[0,0].xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    axs[0,0].set_title('(a) Spring')\n",
        "    axs[0,0].set_xlabel('')\n",
        "    axs[0,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "    axs[0,0].set_xticks(pd.date_range('2000-03-01','2000-05-31', freq='MS'))\n",
        "    axs[0,0].set_xticklabels([\"Mar\",'Apr','May'])\n",
        "    axs[0,0].set(ylim=(0, 7000))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    summer_mask = np.logical_and( foobar['OB_TIME'] >= '2000-06-01', foobar['OB_TIME'] <= '2000-08-31')\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(15,8))\n",
        "    axs[0,1] = sns.lineplot( ax=axs[0,1], data=foobar[summer_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[0,1].xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    axs[0,1].set_title('(b) Summer')\n",
        "    axs[0,1].set_xlabel('')\n",
        "    axs[0,1].set_ylabel('')\n",
        "    axs[0,1].set_xticks(pd.date_range('2000-6','2000-08-31', freq='MS'))\n",
        "    axs[0,1].set_xticklabels([\"Jun\",'Jul','Aug'])\n",
        "    axs[0,1].set(ylim=(0, 7000))\n",
        "\n",
        "\n",
        "    autumn_mask = np.logical_and( foobar['OB_TIME'] >= '2000-09-01', foobar['OB_TIME'] <= '2000-11-30')\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(15,8))\n",
        "    axs[1,0] = sns.lineplot( ax=axs[1,0], data=foobar[autumn_mask], x='OB_TIME', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,0].xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    axs[1,0].set_title('(c) Autumn')\n",
        "    axs[1,0].set_xlabel('Month')\n",
        "    axs[1,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "    axs[1,0].set_xticks(pd.date_range('2000-9','2000-11-30', freq='MS'))\n",
        "    axs[1,0].set_xticklabels([\"Sep\",'Oct','Nov'])\n",
        "    axs[1,0].set(ylim=(0, 7000))\n",
        "\n",
        "\n",
        "    foobar = combined_data_with_nans_daily['2013-12-01':'2014-2'];\n",
        "    foobar.index = np.arange( len( combined_data_with_nans_daily['2013-12-01':'2014-2'].index ) )\n",
        "    foobar = foobar.assign( year='2013' )\n",
        "\n",
        "    for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
        "        temp = combined_data_with_nans_daily[ str(year)+'-12-01': str(year+1)+'-2'];\n",
        "        temp.index = np.arange( len( combined_data_with_nans_daily[str(year)+'-12-01': str(year+1)+'-2'].index ) )\n",
        "        temp = temp.assign( year=str(year) )\n",
        "\n",
        "        foobar = foobar.append( temp )\n",
        "\n",
        "    foobar = foobar.reset_index()\n",
        "\n",
        "    foobar = foobar.rename(columns={'index':'day'})\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(15,8))\n",
        "    axs[1,1] = sns.lineplot( ax=axs[1,1], data=foobar, x='day', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,1].xaxis.set_major_formatter( DateFormatter('%m') )\n",
        "    axs[1,1].set_title('(d) Winter')\n",
        "    axs[1,1].set_xlabel('Month')\n",
        "    axs[1,1].set_ylabel('')\n",
        "    axs[1,1].set_yticks( np.arange(0, 8000, 1000) )\n",
        "    axs[1,1].set_xticks( np.arange(0,91,30) )\n",
        "    axs[1,1].set_xticklabels([\"Dec\",'Jan','Feb'])\n",
        "    axs[1,1].set(ylim=(0, 7000))\n",
        "    #    plt.savefig('/Users/lautinyeung/Desktop/foo.pdf',\n",
        "    #            dpi=300,\n",
        "    #            orientation='portrait',\n",
        "    #            bbox_inches='tight', pad_inches=0)\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "foobar = new_combined_data_with_nans['2013-03-01':'2013-05-31'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019','2020']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year+'-03-01':year+'-05-31'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(23,10))\n",
        "    axs[0,0] = sns.lineplot( ax=axs[0,0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[0,0] = sns.lineplot( ax=axs[0,0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[0,0].set_title('(a) Spring')\n",
        "    axs[0,0].set_xlabel(' ')\n",
        "    axs[0,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "    axs[0,0].set(ylim=(0, 350))\n",
        "    axs[0,0].set_xticks( np.arange(0,24) )\n",
        "\n",
        "\n",
        "    foobar = new_combined_data_with_nans['2013-06-01':'2013-08-31'];\n",
        "    foobar = foobar.reset_index();\n",
        "    foobar.index = foobar.OB_TIME.dt.hour;\n",
        "    foobar = foobar.assign( year='2013' )\n",
        "\n",
        "    for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "        temp = new_combined_data_with_nans[year+'-06-01':year+'-08-31'];\n",
        "        temp = temp.reset_index();\n",
        "        temp.index = temp.OB_TIME.dt.hour;\n",
        "        temp = temp.assign( year=year )\n",
        "\n",
        "        foobar = foobar.append(temp)\n",
        "\n",
        "    foobar.index.name='hourofday'\n",
        "    foobar = foobar.reset_index()\n",
        "\n",
        "\n",
        "    axs[0,1] = sns.lineplot( ax=axs[0,1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[0,1] = sns.lineplot( ax=axs[0,1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[0,1].set_title('(b) Summer')\n",
        "    axs[0,1].set_xlabel(' ')\n",
        "    axs[0,1].set_ylabel('')\n",
        "    axs[0,1].set_xticks( np.arange(0,24) )\n",
        "    axs[0,1].set(ylim=(0, 350))\n",
        "\n",
        "\n",
        "    foobar = new_combined_data_with_nans['2013-09-01':'2013-11-30'];\n",
        "    foobar = foobar.reset_index();\n",
        "    foobar.index = foobar.OB_TIME.dt.hour;\n",
        "    foobar = foobar.assign( year='2013' )\n",
        "\n",
        "    for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "        temp = new_combined_data_with_nans[year+'-09-01':year+'-11-30'];\n",
        "        temp = temp.reset_index();\n",
        "        temp.index = temp.OB_TIME.dt.hour;\n",
        "        temp = temp.assign( year=year )\n",
        "\n",
        "        foobar = foobar.append(temp)\n",
        "\n",
        "    foobar.index.name='hourofday'\n",
        "    foobar = foobar.reset_index()\n",
        "\n",
        "\n",
        "    axs[1,0] = sns.lineplot( ax=axs[1,0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,0] = sns.lineplot( ax=axs[1,0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,0].set_title('(c) Autumn')\n",
        "    axs[1,0].set_xlabel('Hour of Day')\n",
        "    axs[1,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "    axs[1,0].set_xticks( np.arange(0,24) )\n",
        "    axs[1,0].set(ylim=(0, 350))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    foobar = new_combined_data_with_nans['2013-12-01':'2014-2'];\n",
        "    foobar = foobar.reset_index();\n",
        "    foobar.index = foobar.OB_TIME.dt.hour;\n",
        "    foobar = foobar.assign( year='2013' )\n",
        "\n",
        "    for year in [2014, 2015, 2016, 2017, 2018, 2019, 2020]:\n",
        "\n",
        "        temp = new_combined_data_with_nans[ str(year)+'-12-01': str(year+1)+'-2' ];\n",
        "        temp = temp.reset_index();\n",
        "        temp.index = temp.OB_TIME.dt.hour;\n",
        "        temp = temp.assign( year=str(year) )\n",
        "\n",
        "        foobar = foobar.append(temp)\n",
        "\n",
        "    foobar.index.name='hourofday'\n",
        "    foobar = foobar.reset_index()\n",
        "\n",
        "\n",
        "    axs[1,1] = sns.lineplot( ax=axs[1,1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,1] = sns.lineplot( ax=axs[1,1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    axs[1,1].set_title('(d) Winter')\n",
        "    axs[1,1].set_xlabel('Hour of Day')\n",
        "    axs[1,1].set_ylabel('')\n",
        "    axs[1,1].set_xticks( np.arange(0,24) )\n",
        "    axs[1,1].set(ylim=(0, 350))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = new_combined_data_with_nans['2013-03-01':'2013-05-31'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019','2020']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year+'-03-01':year+'-05-31'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure( figsize=(15,8) )\n",
        "    ax = sns.lineplot( label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax = sns.lineplot( label='weekend', ax=ax, data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set(ylim=(125, 350))\n",
        "    ax.set_xticks( np.arange(0,24) )\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = new_combined_data_with_nans['2013-06-01':'2013-08-31'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year+'-06-01':year+'-08-31'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure( figsize=(15,8) )\n",
        "    ax = sns.lineplot( label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax = sns.lineplot( label='weekend', ax=ax, data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Summer (June - August) hourly bin_kwh 2013-2019')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks( np.arange(0,24) )\n",
        "    ax.set(ylim=(125, 350))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = new_combined_data_with_nans['2013-09-01':'2013-11-30'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year+'-09-01':year+'-11-30'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax = sns.lineplot( label='weekend', ax=ax, data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Autumn (September - November) hourly bin_kwh 2013-2019')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks( np.arange(0,24) )\n",
        "    ax.set(ylim=(125, 350))\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "foobar = new_combined_data_with_nans['2013-12-01':'2014-2'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in [2014, 2015, 2016, 2017, 2018, 2019, 2020]:\n",
        "\n",
        "    temp = new_combined_data_with_nans[ str(year)+'-12-01': str(year+1)+'-2' ];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=str(year) )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    ax = sns.lineplot( label='weekend', ax=ax, data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Winter (December - Feburary) hourly bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    ax.set_xticks( np.arange(0,24) )\n",
        "    ax.set(ylim=(125, 350))\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ]['2013-03-01':'2013-05-31'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][year+'-03-01':year+'-05-31'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\", label='Spring')\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_xticks( np.arange(0,24) )\n",
        "\n",
        "\n",
        "foobar = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ]['2013-06-01':'2013-08-31'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][year+'-06-01':year+'-08-31'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.lineplot( data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\", ax=ax, label='Summer')\n",
        "#ax.set_title('Summer (June - August) hourly bin_kwh 2013-2019')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "foobar = new_combined_data_with_nans['2013-09-01':'2013-11-30'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year+'-09-01':year+'-11-30'];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.lineplot( data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\", ax=ax, label='Autumn')\n",
        "#ax.set_title('Autumn (September - November) hourly bin_kwh 2013-2019')\n",
        "\n",
        "\n",
        "\n",
        "foobar = new_combined_data_with_nans['2013-12-01':'2014-2'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in [2014, 2015, 2016, 2017, 2018, 2019]:\n",
        "\n",
        "    temp = new_combined_data_with_nans[ str(year)+'-12-01': str(year+1)+'-2' ];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=str(year) )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "ax = sns.lineplot( data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='bin_kwh', err_style='band', ci=\"sd\", ax=ax, label='Winter')\n",
        "ax.legend()\n",
        "#ax.set_title('Winter (December - Feburary) hourly bin_kwh 2013-2020')\n",
        "ax.set_xlabel('Hour of Day')\n",
        "ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "ax.set_xticks( np.arange(0,24) )\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = new_combined_data_with_nans['2013'];\n",
        "foobar = foobar.reset_index();\n",
        "foobar.index = foobar.OB_TIME.dt.hour;\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = new_combined_data_with_nans[year];\n",
        "    temp = temp.reset_index();\n",
        "    temp.index = temp.OB_TIME.dt.hour;\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append(temp)\n",
        "\n",
        "foobar.index.name='hourofday'\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(15,5))\n",
        "\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='AIR_TEMPERATURE', err_style='band', ci=\"sd\")\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='AIR_TEMPERATURE', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[0].set_xlabel('Hour of Day')\n",
        "    axs[0].set_ylabel('Temperature (Degree Celcius)')\n",
        "    axs[0].set(ylim=(0, 20))\n",
        "    axs[0].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    #plt.figure( figsize=(15,8) )\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='DEWPOINT', err_style='band', ci=\"sd\")\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='DEWPOINT', err_style='band', ci=\"sd\")\n",
        "    axs[1].set_xlabel('Hour of Day')\n",
        "    axs[1].set_ylabel('')\n",
        "    axs[1].set(ylim=(0, 20))\n",
        "    axs[1].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    #plt.figure( figsize=(15,8) )\n",
        "    axs[2] = sns.lineplot( ax=axs[2], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='WETB_TEMP', err_style='band', ci=\"sd\")\n",
        "    axs[2] = sns.lineplot( ax=axs[2], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='WETB_TEMP', err_style='band', ci=\"sd\")\n",
        "    axs[2].set_xlabel('Hour of Day')\n",
        "    axs[2].set_ylabel('')\n",
        "    axs[2].set(ylim=(0, 20))\n",
        "    axs[2].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='MSL_PRESSURE', err_style='band', ci=\"sd\")\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='MSL_PRESSURE', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[0].set_xlabel('Hour of Day')\n",
        "    axs[0].set_ylabel('Pressure (hPa)')\n",
        "    axs[0].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='STN_PRES', err_style='band', ci=\"sd\")\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='STN_PRES', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[1].set_xlabel('Hour of Day')\n",
        "    axs[1].set_ylabel('')\n",
        "    #ax.set(ylim=(0, 16))\n",
        "    axs[1].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_combined_data_with_nans.shape\n",
        "new_combined_data_with_nans[new_combined_data_with_nans['WMO_HR_SUN_DUR'].isna()].shape\n",
        "foobar[ np.logical_and(foobar['hourofday'] == 0, np.logical_or(foobar['WMO_HR_SUN_DUR'] == 1, foobar['WMO_HR_SUN_DUR'] == 0))]\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='DRV_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='DRV_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[0].set_xlabel('Hour of Day')\n",
        "    axs[0].set_ylabel('Duration of sunshine (hours)')\n",
        "    axs[0].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='WMO_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='WMO_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[1].set_xlabel('Hour of Day')\n",
        "    axs[1].set_ylabel('')\n",
        "    #ax.set(ylim=(0, 16))\n",
        "    axs[1].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar[np.logical_and(foobar['hourofday'] == 21, foobar['PRCP_AMT'] == 0)]\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
        "\n",
        "    i=0\n",
        "    ylabels = ['Relative Humidity (%)', 'Precipitation amount (mm)', 'Cloud-base height (decametres)', 'Visibility (decametres)']\n",
        "    for feature in ['RLTV_HUM','PRCP_AMT','CLD_BASE_HT','VISIBILITY']:\n",
        "\n",
        "        sns.lineplot( ax=axs[int(i/2),i%2], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y=feature, err_style='band', ci=\"sd\")\n",
        "        sns.lineplot( ax=axs[int(i/2),i%2], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y=feature, err_style='band', ci=\"sd\")\n",
        "        axs[int(i/2),i%2].set_title(feature)\n",
        "        axs[int(i/2),i%2].set_xlabel('Hour of Day')\n",
        "        axs[int(i/2),i%2].set_ylabel(ylabels[i])\n",
        "        axs[int(i/2),i%2].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "        i=i+1\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='WIND_SPEED', err_style='band', ci=\"sd\")\n",
        "    sns.lineplot( ax=ax, label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='WIND_SPEED', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_ylabel('Windspeed (knots)')\n",
        "    ax.set_xticks( np.arange(0,24, 1) )\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='RLTV_HUM', err_style='band', ci=\"sd\")\n",
        "    axs[0] = sns.lineplot( ax=axs[0], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='RLTV_HUM', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[0].set_xlabel('Hour of Day')\n",
        "    axs[0].set_ylabel('Relative Humidity (%)')\n",
        "    axs[0].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekday', data=foobar[foobar['WEEKEND'] == 0], x='hourofday', y='WMO_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    axs[1] = sns.lineplot( ax=axs[1], label='weekend', data=foobar[foobar['WEEKEND'] == 1], x='hourofday', y='WMO_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    #ax.set_title('Spring (March - May) hourly bin_kwh 2013-2020')\n",
        "    axs[1].set_xlabel('Hour of Day')\n",
        "    axs[1].set_ylabel('Relative Humidity (%)')\n",
        "    #ax.set(ylim=(0, 16))\n",
        "    axs[1].set_xticks( np.arange(0,24, 4) )\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = combined_data_with_nans_weekly['2013'];\n",
        "foobar.index = combined_data_with_nans_weekly['2013'].index.to_series().dt.weekofyear.to_numpy()\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = combined_data_with_nans_weekly[ year ];\n",
        "    temp.index = combined_data_with_nans_weekly[ year ].index.to_series().dt.weekofyear.to_numpy()\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "foobar = foobar.rename( columns={'index':'weekofyear'})\n",
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar, x='weekofyear', y='AIR_TEMPERATURE', label='AIR_TEMPERATURE', err_style='band', ci=\"sd\")\n",
        "    sns.lineplot( ax=ax, data=foobar, x='weekofyear', y='DEWPOINT', label='DEWPOINT', err_style='band', ci=\"sd\")\n",
        "    sns.lineplot( ax=ax, data=foobar, x='weekofyear', y='WETB_TEMP', label='WETB_TEMP', err_style='band', ci=\"sd\")\n",
        "    ax.legend()\n",
        "    ax.set_xticks(np.arange(1,53,4+1/3))\n",
        "    ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Temperature (Degree Celcius)')\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar, x='weekofyear', y='MSL_PRESSURE', label='MSL_PRESSURE', err_style='band', ci=\"sd\")\n",
        "    sns.lineplot( ax=ax, data=foobar, x='weekofyear', y='STN_PRES', label='STN_PRES', err_style='band', ci=\"sd\")\n",
        "    ax.legend()\n",
        "    ax.set_xticks(np.arange(1,53,4+1/3))\n",
        "    ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Pressure (hPa)')\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "with sns.axes_style(\"whitegrid\"):\n",
        "    plt.figure(figsize=(15,8))\n",
        "    ax = sns.lineplot( data=foobar, x='weekofyear', y='WMO_HR_SUN_DUR', label='WMO_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    sns.lineplot( ax=ax, data=foobar, x='weekofyear', y='DRV_HR_SUN_DUR', label='DRV_HR_SUN_DUR', err_style='band', ci=\"sd\")\n",
        "    ax.legend()\n",
        "    ax.set_xticks(np.arange(1,53,4+1/3))\n",
        "    ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_ylabel('Duration of sunshine (hours)')\n",
        "    plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#with sns.axes_style(\"whitegrid\"):\n",
        "fig, axs = plt.subplots(2, 2, figsize=(15,10))\n",
        "\n",
        "i=0\n",
        "ylabels = ['Relative Humidity (%)', 'Precipitation amount (mm)', 'Cloud-base height (decametres)', 'Visibility (decametres)']\n",
        "for feature in ['RLTV_HUM','PRCP_AMT','CLD_BASE_HT','VISIBILITY']:\n",
        "\n",
        "    sns.lineplot( ax=axs[int(i/2),i%2], data=foobar, x='weekofyear', y=feature, err_style='band', ci=\"sd\")\n",
        "    axs[int(i/2),i%2].set_title(feature)\n",
        "    axs[int(i/2),i%2].set_xlabel('Month')\n",
        "    axs[int(i/2),i%2].set_ylabel(ylabels[i])\n",
        "    axs[int(i/2),i%2].set_xticks(np.arange(1,53,8+2/3))\n",
        "    axs[int(i/2),i%2].set_xticklabels(['Jan',\"Mar\",'May','Jul','Sep','Nov'])\n",
        "\n",
        "    i=i+1\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(4, 4, figsize=(15,15))\n",
        "\n",
        "for i in range(13):\n",
        "    feature = combined_data_with_nans.columns[i];\n",
        "\n",
        "    sns.lineplot( ax=axs[int(i/4),i%4], data=foobar, x='weekofyear', y=feature, err_style='band', ci=\"sd\")\n",
        "    axs[int(i/4),i%4].set_title(feature)\n",
        "    axs[int(i/4),i%4].set_xlabel('Month')\n",
        "    axs[int(i/4),i%4].set_xticks(np.arange(1,53,8+2/3))\n",
        "    axs[int(i/4),i%4].set_xticklabels(['Jan',\"Mar\",'May','Jul','Sep','Nov'])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "fig, axs = plt.subplots(3, 4, figsize=(15,15))\n",
        "\n",
        "for i in range(12):\n",
        "    feature = combined_data_with_nans.columns[i];\n",
        "\n",
        "    ax = sns.lineplot( ax=axs[int(i/4),i%4], data=foobar[foobar['year'] != '2020'], x='weekofyear', y=feature, hue='year', legend=False)\n",
        "    axs[int(i/4),i%4].set_title(feature)\n",
        "    axs[int(i/4),i%4].set_xlabel('Month')\n",
        "    axs[int(i/4),i%4].set_xticks(np.arange(1,53,8+2/3))\n",
        "    axs[int(i/4),i%4].set_xticklabels(['Jan',\"Mar\",'May','Jul','Sep','Nov'])\n",
        "\n",
        "\n",
        "fig.legend(labels=['2013','2014', '2015', '2016', '2017', '2018', '2019'],   # The labels for each line\n",
        "           loc=\"center\",   # Position of legend\n",
        "           borderaxespad=0.1,    # Small spacing around legend box\n",
        "           title=\"Year\"  # Title for the legend\n",
        "           )\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ax = WindroseAxes.from_ax()\n",
        "ax.bar( new_combined_data_with_nans_weekly['WIND_DIRECTION'], new_combined_data_with_nans_weekly['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "ax.set_title('Annual')\n",
        "ax.legend(labels=['[0.0 - 8.0)','[8.0 - 16.0)','[16.0 - 24.0)', '[24.0 - 32.0)', '[32.0 - infinity)'],   # The labels for each line\n",
        "           loc=\"lower right\",   # Position of legend\n",
        "           borderaxespad=0.1,    # Small spacing around legend box\n",
        "           title=\"Wind Speed Colour Guide\"  # Title for the legend\n",
        "           )\n",
        "\n",
        "plt.tight_layout()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "foobar = combined_data_with_nans_weekly['2013'];\n",
        "foobar.index = pd.to_datetime( combined_data_with_nans_weekly['2013'].index.strftime('%m-%d-00') )\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in ['2014', '2015', '2016', '2017', '2018', '2019', '2020']:\n",
        "\n",
        "    temp = combined_data_with_nans_weekly[ year ];\n",
        "    temp.index = pd.to_datetime( combined_data_with_nans_weekly[ year ].index.strftime('%m-%d-00') )\n",
        "    temp = temp.assign( year=year )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "fig=plt.figure( figsize=(20,30) )\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 1, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( foobar[ spring_mask ]['WIND_DIRECTION'], foobar[ spring_mask ]['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "ax.set_title('Spring')\n",
        "\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 2, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( foobar[ summer_mask ]['WIND_DIRECTION'], foobar[ summer_mask ]['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "ax.set_title('Summer')\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 3, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( foobar[ autumn_mask ]['WIND_DIRECTION'], foobar[ autumn_mask ]['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "ax.set_title('Autumn')\n",
        "\n",
        "\n",
        "foobar = combined_data_with_nans_weekly['2013-12-01':'2014-2'];\n",
        "foobar.index = np.arange( len( combined_data_with_nans_weekly['2013-12-01':'2014-2'].index ) )\n",
        "foobar = foobar.assign( year='2013' )\n",
        "\n",
        "for year in [2014, 2015, 2016, 2017, 2018, 2019, 2020]:\n",
        "    temp = combined_data_with_nans_weekly[ str(year)+'-12-01': str(year+1)+'-2'];\n",
        "    temp.index = np.arange( len( combined_data_with_nans_weekly[str(year)+'-12-01': str(year+1)+'-2'].index ) )\n",
        "    temp = temp.assign( year=str(year) )\n",
        "\n",
        "    foobar = foobar.append( temp )\n",
        "\n",
        "foobar = foobar.reset_index()\n",
        "\n",
        "foobar = foobar.rename(columns={'index':'day'})\n",
        "\n",
        "\n",
        "ax = fig.add_subplot(2, 2, 4, projection=\"windrose\", rmax = 50)\n",
        "ax.bar( foobar['WIND_DIRECTION'], foobar['WIND_SPEED'], normed=True, bins=np.arange(0,37,8), nsector=8, opening=0.8, edgecolor='white')\n",
        "ax.set_title('Winter')\n",
        "\n",
        "fig.legend(labels=['[0.0 - 8.0)','[8.0 - 16.0)','[16.0 - 24.0)', '[24.0 - 32.0)', '[32.0 - infinity)'],   # The labels for each line\n",
        "           loc=\"center\",   # Position of legend\n",
        "           borderaxespad=0.1,    # Small spacing around legend box\n",
        "           title=\"Wind Speed Colour Guide\"  # Title for the legend\n",
        "           )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HDD CDD"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fix, axs = plt.subplots( 1,2, figsize=(20,10))\n",
        "plt.figure(figsize=(15,12)) #10,15\n",
        "sns.heatmap(\n",
        "    combined_data_with_nans.iloc[:,:-1].corr(method='pearson'),\n",
        "    cmap=plt.cm.coolwarm,\n",
        "    vmin=-1.0,\n",
        "    vmax=1.0,\n",
        "    linewidths=0.1,\n",
        "    linecolor='white',\n",
        "    square=True,\n",
        "    annot=True,\n",
        "    #ax=axs[0]\n",
        "    annot_kws={\"size\": 15}\n",
        ")\n",
        "\n",
        "axs[0].set_title('Hourly')\n",
        "\n",
        "\n",
        "#plt.figure(figsize=(20,15))\n",
        "plt.figure(figsize=(15,12))\n",
        "sns.heatmap(\n",
        "    combined_data_with_nans_weekly.iloc[:,:-1].corr(method='pearson'),\n",
        "    cmap=plt.cm.coolwarm,\n",
        "    vmin=-1.0,\n",
        "    vmax=1.0,\n",
        "    linewidths=0.1,\n",
        "    linecolor='white',\n",
        "    square=True,\n",
        "    annot=True,\n",
        "    #ax=axs[1],\n",
        "    annot_kws={\"size\": 15}\n",
        ")\n",
        "axs[1].set_title('Weekly')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "def to_DD( data ):\n",
        "    temp = data['AIR_TEMPERATURE'];\n",
        "\n",
        "    # arbritary, follow literatur.  Can base on summary stat, BUT BECAREFUL of data leak ( train set vs. test set)\n",
        "    hdd_base = 15.5;\n",
        "    #hdd_base = 20;\n",
        "    cdd_base = 20;\n",
        "\n",
        "    hdd = np.maximum( hdd_base - temp, np.zeros_like(temp)).sum()\n",
        "    cdd = np.maximum( temp - cdd_base, np.zeros_like(temp)).sum()\n",
        "\n",
        "    return pd.Series([hdd,cdd], index=['WHDH','WCDH'])\n",
        "\n",
        "dd = combined_data_with_nans[ ['AIR_TEMPERATURE'] ].groupby( pd.Grouper(freq='1w') ).apply( to_DD )\n",
        "\n",
        "new_combined_data_with_nans_weekly = pd.concat( [dd.iloc[1:], combined_data_with_nans_weekly], axis=1 )\n",
        "\n",
        "new_combined_data_with_nans_weekly = new_combined_data_with_nans_weekly.assign(\n",
        "        FRINGE=new_combined_data_with_nans_weekly.index.to_series().map( is_fringe ).to_numpy(),\n",
        "        WINTER_CLOSURE=new_combined_data_with_nans_weekly.index.to_series().map( is_winter_closure ).to_numpy()\n",
        "    )\n",
        "\n",
        "new_combined_data_with_nans_weekly\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15,12))\n",
        "sns.heatmap(\n",
        "    new_combined_data_with_nans_weekly.drop(['bin_kwh','WINTER_CLOSURE','FRINGE'], axis=1).corr(method='kendall'),\n",
        "    cmap=plt.cm.coolwarm,\n",
        "    vmin=-1.0,\n",
        "    vmax=1.0,\n",
        "    linewidths=0.1,\n",
        "    linecolor='white',\n",
        "    square=True,\n",
        "    annot=True,\n",
        "    annot_kws={\"size\": 15}\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import rpy2;\n",
        "%load_ext rpy2.ipython\n",
        "\n",
        "import rpy2.robjects as ro;\n",
        "\n",
        "from rpy2.robjects import pandas2ri;\n",
        "from rpy2.robjects import default_converter\n",
        "from rpy2.robjects.conversion import localconverter;\n",
        "\n",
        "from rpy2.robjects.packages import importr;\n",
        "\n",
        "utils = importr(\"utils\");\n",
        "grdevices = importr('grDevices');\n",
        "infenergy = importr('infenergy');\n",
        "\n",
        "\n",
        "def help_r( python_name ):\n",
        "    print( str( utils.help( python_name.replace('_','.') ) ) );\n",
        "\n",
        "combined_data_with_nans.index[0]\n",
        "combined_data_with_nans.index[-1]\n",
        "\n",
        "\n",
        "\n",
        "ro.r('''\n",
        "from <- \"2011-07-06\"\n",
        "to <- \"2020-06-01\"\n",
        "\n",
        "## Server & Forum UPS data\n",
        "server1 <- get.ups.hourly(from, \"2017-07-16\", upss=c(\"serverL\", \"serverR\"), power.factor=NA, infer.missing.data=FALSE)\n",
        "server2 <- get.ups.hourly(\"2017-07-16\", \"2018-02-12\", upss=c(\"serverL\", \"serverR\"), power.factor=NA, infer.missing.data=TRUE)\n",
        "server3 <- get.ups.hourly(\"2018-02-12\", to, upss=c(\"serverL\", \"serverR\"), power.factor=NA, infer.missing.data=FALSE)\n",
        "server <- rbind(server1, server2, server3)\n",
        "attr(server, \"to\") <- as.POSIXlt(to, tz=\"GMT\")\n",
        "\n",
        "## Separate out bits where we know only forumB was working - otherwise\n",
        "## the system tries to compensate for the missing forumA\n",
        "## forum <- get.ups.hourly(from, to, upss=c(\"forumA\", \"forumB\"),  power.factor=0.9)\n",
        "forum1 <-  get.ups.hourly(from, \"2013-01-03\", upss=c(\"forumA\", \"forumB\"), power.factor=0.9)\n",
        "forum2 <-  get.ups.hourly(\"2013-01-03\", \"2013-03-18\", upss=c(\"forumB\"), power.factor=0.9)\n",
        "forum3 <-  get.ups.hourly(\"2013-03-18\", \"2013-03-21\", upss=c(\"forumA\", \"forumB\"), power.factor=0.9)\n",
        "forum4 <-  get.ups.hourly(\"2013-03-21\", to, upss=c(\"forumB\"), power.factor=0.9)\n",
        "forum <- rbind(forum1, forum2, forum3, forum4)\n",
        "attr(forum, \"to\") <- as.POSIXlt(to, tz=\"GMT\")\n",
        "''')\n",
        "\n",
        "ro.r('''\n",
        "## Read in the main meter data: the first part comes from the\n",
        "## university; the second from meter readings\n",
        "## dates *inclusive* dates\n",
        "meter <- hourly(get.inf.meter.data(\"2013-01-21\", to))\n",
        "dat <- rbind(meter)\n",
        "attr(dat, \"to\") <- as.POSIXlt(to, tz=\"GMT\")\n",
        "\n",
        "## Set missing server readings to zero\n",
        "server$kWh[is.na(server$kWh)] <-0\n",
        "forum$kWh[is.na(forum$kWh)] <-0\n",
        "\n",
        "combine <- combine.data.hourly(list(Server=server, Forum=forum), tot=dat)\n",
        "\n",
        "\n",
        "par(mar=c(2,4,1,0))\n",
        "combine.weekly <- weekly(combine) # THE DATA FRAME\n",
        "''')\n",
        "\n",
        "\n",
        "\n",
        "data_ups_combine        = ro.r['combine'] # as an r dataframe\n",
        "data_ups_combine_weekly = ro.r['combine.weekly'] # as an r dataframe\n",
        "\n",
        "with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "  data_ups_combine_converted = ro.conversion.rpy2py( data_ups_combine );\n",
        "  data_ups_combine_weekly_converted = ro.conversion.rpy2py( data_ups_combine_weekly );\n",
        "\n",
        "data_ups_combine_converted = data_ups_combine_converted.set_index('Time')\n",
        "data_ups_combine_weekly_converted = data_ups_combine_weekly_converted.set_index('Time')\n",
        "\n",
        "data_ups_combine_converted_filtered = data_ups_combine_converted[\\\n",
        "    combined_data_with_nans.index[0].strftime(\"%m/%d/%Y, %H:%M:%S\"):\\\n",
        "        combined_data_with_nans.index[-1].strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "        ]\n",
        "\n",
        "\n",
        "data_ups_combine_converted_filtered.sum( axis = 1 ).resample('W').sum().plot()\n",
        "\n",
        "new_combined_data_with_nans['bin_kwh'].resample('W').sum().plot()\n",
        "\n",
        "\n",
        "data_ups_combine_converted_filtered.describe()\n",
        "data_ups_combine_converted_filtered.sum( axis = 1 ).describe()\n",
        "\n",
        "\n",
        "data_ups_combine_converted_filtered.resample('W').sum().plot()\n",
        "data_ups_combine_converted_filtered.sum( axis = 1 ).resample('W').sum().plot()\n",
        "\n",
        "combined_data_with_nans['bin_kwh']['2014':'2018'].resample('W').sum().plot()\n",
        "data_ups_combine_converted_filtered.sum( axis=1 )['2014':'2018'].resample('W').sum().plot()\n",
        "data_ups_combine_converted_filtered['Forum']['2014-01-20'].plot()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODELLING"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import make_scorer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.feature_selection import f_regression\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Lasso\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import explained_variance_score\n",
        "\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# feature selection\n",
        "# def select_features(X_train, y_train, X_test):\n",
        "# \tfs = SelectKBest(score_func=f_regression, k=6)\n",
        "# \tfs.fit(X_train, y_train)\n",
        "# \t# auto select features ( transform )\n",
        "# \tX_train_fs = fs.transform(X_train)\n",
        "# \tX_test_fs = fs.transform(X_test)\n",
        "# \treturn X_train_fs, X_test_fs, fs\n",
        "\n",
        "\n",
        "# weekend_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','bin_kwh']\n",
        "# weekday_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','DRV_HR_SUN_DUR','bin_kwh']\n",
        "\n",
        "more_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','DRV_HR_SUN_DUR','PRCP_AMT','bin_kwh']\n",
        "\n",
        "more_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','DRV_HR_SUN_DUR','PRCP_AMT','bin_kwh']\n",
        "\n",
        "new_combined_data_with_nans.columns\n",
        "\n",
        "# X, y = new_combined_data_with_nans_weekly.iloc[:,:-1].assign(week=np.arange(len(new_combined_data_with_nans_weekly))).dropna(), new_combined_data_with_nans_weekly.dropna()['bin_kwh']\n",
        "X, y = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][weekday_features].dropna().iloc[:,:-1], new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][weekday_features].dropna()['bin_kwh']\n",
        "#X, y = new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][weekday_features].dropna().iloc[1:,:-1], new_combined_data_with_nans[ new_combined_data_with_nans['WEEKEND'] == 0 ][weekday_features].dropna()['bin_kwh'].diff().iloc[1:]\n",
        "\n",
        "#X, y = X[['WMO_HR_SUN_DUR','RLTV_HUM']], y\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15, random_state=1)\n",
        "# feature selection\n",
        "#X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
        "\n",
        "\n",
        "#for i in fs.scores_.argsort()[::-1]:\n",
        "#\tprint(f'{new_combined_data_with_nans_weekly.iloc[:,:-1].assign(week=np.arange(len(new_combined_data_with_nans_weekly))).columns[i]}: {fs.scores_[i]}')\n",
        "# plot the scores\n",
        "#plt.bar([i for i in fs.scores_.argsort()[::-1]], fs.scores_[fs.scores_.argsort()[::-1]])\n",
        "#plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "X_train.columns\n",
        "#sns.scatterplot(x=X_train['PRCP_AMT'], y=y_train)\n",
        "sns.scatterplot(x=X_train['WIND_SPEED'], y=y_train)\n",
        "sns.scatterplot(x=X_train['AIR_TEMPERATURE'], y=y_train)\n",
        "sns.scatterplot(x=X_train['RLTV_HUM'], y=y_train)\n",
        "#sns.scatterplot(x=X_train['MSL_PRESSURE'], y=y_train)\n",
        "sns.scatterplot(x=X_train['DRV_HR_SUN_DUR'], y=y_train)\n",
        "sns.scatterplot(x=X_train['VISIBILITY'], y=y_train)\n",
        "sns.scatterplot(x=X_train['CLD_BASE_HT'], y=y_train)\n",
        "\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# fit the model\n",
        "model = LinearRegression()\n",
        "#model.fit(X_train_fs, y_train)\n",
        "#model.fit(X_train, y_train)\n",
        "\n",
        "# evaluate the model\n",
        "scoring = {'RMSE': make_scorer( lambda y_true, y_pred: mean_squared_error(y_true, y_pred)**0.5 ),\n",
        "           'MAPE': make_scorer( mean_absolute_percentage_error ),\n",
        "           'Explained Variance': make_scorer( explained_variance_score ),\n",
        "           'R2': make_scorer( r2_score )}\n",
        "scores = cross_validate(model, X, y, scoring=scoring,\n",
        "                         cv=5, return_train_score=True)\n",
        "\n",
        "scores\n",
        "\n",
        "print('Train scores: \\n\\n'+\\\n",
        "'RMSE: {} += {}\\n'.format(scores['train_RMSE'].mean(), scores['train_RMSE'].std())+\\\n",
        "'MAPE: {} , {}\\n'.format(scores['train_MAPE'].mean(), scores['train_MAPE'].std())+\\\n",
        "'Explained Variance: {} , {}\\n'.format(scores['train_Explained Variance'].mean(), scores['train_Explained Variance'].std())+\\\n",
        "'R2: {} , {}\\n'.format(scores['train_R2'].mean(), scores['train_R2'].std())\n",
        ")\n",
        "\n",
        "print('Test scores: \\n\\n'+\\\n",
        "'RMSE: {} += {}\\n'.format(scores['test_RMSE'].mean(), scores['test_RMSE'].std())+\\\n",
        "'MAPE: {} , {}\\n'.format(scores['test_MAPE'].mean(), scores['test_MAPE'].std())+\\\n",
        "'Explained Variance: {} , {}\\n'.format(scores['test_Explained Variance'].mean(), scores['test_Explained Variance'].std())+\\\n",
        "'R2: {} , {}\\n'.format(scores['test_R2'].mean(), scores['test_R2'].std())\n",
        ")\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X_train, y_train)\n",
        "\n",
        "print('Plot model')\n",
        "#yhat = model.predict(X_test_fs)\n",
        "yhat = plot_model.predict(X_test)\n",
        "# evaluate predictions\n",
        "rmse = mean_squared_error(y_test, yhat)**0.5\n",
        "mape = mean_absolute_percentage_error(y_test, yhat)\n",
        "expl_var = explained_variance_score(y_test, yhat)\n",
        "r2 = r2_score(y_test, yhat)\n",
        "print('RMSE: %.3f' % rmse)\n",
        "print('MAPE: %.3f percent' % mape)\n",
        "\n",
        "#print('RMSE: %.3f' % rmse)\n",
        "#print('MAPE: %.3f percent' % mape)\n",
        "\n",
        "#print('RMSE: %.3f' % rmse)\n",
        "#print('MAPE: %.3f percent' % mape)\n",
        "\n",
        "print('Explained Variance: %.3f' % expl_var)\n",
        "print('R2: %.3f' % r2)\n",
        "\n",
        "#print('Explained Variance: %.3f' % expl_var)\n",
        "#print('R2: %.3f' % r2)\n",
        "\n",
        "# print('Explained Variance: %.3f' % expl_var)\n",
        "# print('R2: %.3f' % r2)\n",
        "\n",
        "#ax=sns.lineplot(x=X_test.index, y=model.predict(X_test_fs))\n",
        "foobar = pd.DataFrame(plot_model.predict(X_test))\n",
        "foobar.index = X_test.index\n",
        "\n",
        "X_train.shape\n",
        "X_test.shape\n",
        "\n",
        "X_train.columns\n",
        "plot_model.coef_\n",
        "X_train.columns[plot_model.coef_.argsort()]\n",
        "\n",
        "#model.coef_\n",
        "\n",
        "#model.coef_\n",
        "\n",
        "ax=foobar.resample('W').mean().plot()\n",
        "y_test.resample('W').mean().plot(ax=ax)\n",
        "\n",
        "#ax=foobar.resample('W').mean().plot()\n",
        "#y_test.resample('W').mean().plot(ax=ax)\n",
        "\n",
        "# ax=foobar.resample('W').mean().plot()\n",
        "# y_test.resample('W').mean().plot(ax=ax)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tsfresh import extract_relevant_features\n",
        "\n",
        "features_filtered_direct = extract_relevant_features(X.reset_index(), y,\n",
        "                                                     column_id='OB_TIME')\n",
        "\n",
        "\n",
        "features_filtered_direct\n",
        "\n",
        "\n",
        "my_model = LinearRegression()\n",
        "my_model.fit(features_filtered_direct, y)\n",
        "\n",
        "\n",
        "# evaluate the model\n",
        "yhat = my_model.predict(features_filtered_direct)\n",
        "# evaluate predictions\n",
        "rmse = mean_squared_error(y, yhat)**0.5\n",
        "print('RMSE: %.3f' % rmse)\n",
        "\n",
        "ax=sns.lineplot(x=features_filtered_direct.index, y=my_model.predict(features_filtered_direct))\n",
        "\n",
        "y.plot(ax=ax)\n",
        "new_combined_data_with_nans_daily.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[ feature for feature in combined_data_with_nans if feature not in hourly_features]\n",
        "# weekend_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','bin_kwh']\n",
        "# weekday_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','DRV_HR_SUN_DUR','bin_kwh']\n",
        "\n",
        "hourly_features = ['WIND_DIRECTION', 'WIND_SPEED', 'CLD_BASE_HT', 'VISIBILITY', 'STN_PRES', 'AIR_TEMPERATURE', 'RLTV_HUM', 'DRV_HR_SUN_DUR', 'PRCP_AMT', 'NO_WIND', 'WEEKEND', 'FRINGE', 'WINTER_CLOSURE', 'bin_kwh']\n",
        "daily_features  = ['WIND_DIRECTION', 'WIND_SPEED', 'CLD_BASE_HT', 'VISIBILITY', 'STN_PRES', 'AIR_TEMPERATURE', 'RLTV_HUM', 'DRV_HR_SUN_DUR', 'PRCP_AMT', 'WEEKEND', 'FRINGE', 'WINTER_CLOSURE', 'bin_kwh']\n",
        "weekly_features = ['WIND_DIRECTION', 'WIND_SPEED', 'CLD_BASE_HT', 'VISIBILITY', 'STN_PRES', 'WHDH', 'WCDH', 'RLTV_HUM', 'DRV_HR_SUN_DUR', 'PRCP_AMT', 'FRINGE', 'WINTER_CLOSURE', 'bin_kwh']\n",
        "time_features = [ 'WEEKEND', 'FRINGE', 'WINTER_CLOSURE','bin_kwh']\n",
        "# more_features = ['AIR_TEMPERATURE', 'WIND_SPEED', 'VISIBILITY', 'RLTV_HUM', 'CLD_BASE_HT','DRV_HR_SUN_DUR','PRCP_AMT','bin_kwh']\n",
        "\n",
        "using_datas = []\n",
        "\n",
        "X, y = new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 0 ][hourly_features].dropna().iloc[:,:-1], new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 0 ][hourly_features].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('weekdays 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "X, y = new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 1 ][hourly_features].dropna().iloc[:,:-1], new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 1 ][hourly_features].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('weekends 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "# X, y = new_combined_data_with_nans.drop('WIND_DIRECTION', axis=1).dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans.drop('WIND_DIRECTION', axis=1).dropna()['bin_kwh']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "X.shape\n",
        "X['NO_WIND'].sum()\n",
        "# X, y = new_combined_data_with_nans[more_features].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[more_features].dropna()['bin_kwh']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "# X, y = new_combined_data_with_nans[['DRV_HR_SUN_DUR', 'AIR_TEMPERATURE']].dropna(), new_combined_data_with_nans[['DRV_HR_SUN_DUR', 'AIR_TEMPERATURE','bin_kwh']].dropna()['bin_kwh']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# for kk in using_datas:\n",
        "#     name, X, y, X_train, X_test, y_train, y_test = kk\n",
        "#     print( X.shape )\n",
        "\n",
        "using_datas.extend([('hourly 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "\n",
        "#X, y = new_combined_data_with_nans_weekly.iloc[:,:-1].assign(week=np.arange(len(new_combined_data_with_nans_weekly))).dropna(), new_combined_data_with_nans_weekly.dropna()['bin_kwh']\n",
        "X, y = new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('weekly 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('daily 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "using_datas = []\n",
        "\n",
        "# X, y = new_combined_data_with_nans.dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans.dropna().join( data_ups_combine_converted_filtered['Other'] )['Other']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "#\n",
        "# using_datas.extend([('ups all', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('hourly 2013-02-01 to 2016-01-31 ', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('daily 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().join( data_ups_combine_converted_filtered['Other'] )['Other']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('Removing UPS hourly 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().join( data_ups_combine_converted_filtered['Other'].resample('D').sum() )['Other']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "using_datas.extend([('Removing UPS daily 2013-02-01 to 2016-01-31', X, y, X_train, X_test, y_train, y_test)])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 3, figsize=(25,8))\n",
        "i=0\n",
        "for dataset in using_datas:\n",
        "\n",
        "    name, X, y, X_train, X_test, y_train, y_test = dataset\n",
        "\n",
        "    print( name )\n",
        "\n",
        "    model = LinearRegression()\n",
        "\n",
        "    # evaluate the model\n",
        "    scoring = {'RMSE': make_scorer( lambda y_true, y_pred: mean_squared_error(y_true, y_pred)**0.5 ),\n",
        "               'MAPE': make_scorer( mean_absolute_percentage_error ),\n",
        "               'Explained Variance': make_scorer( explained_variance_score ),\n",
        "               'R2': make_scorer( r2_score )}\n",
        "    shuffler = ShuffleSplit(n_splits=10, test_size=0.33, random_state=1)\n",
        "    scores = cross_validate(model, X, y, scoring=scoring,\n",
        "                             cv=shuffler, return_train_score=True)\n",
        "\n",
        "    print('Train scores: \\n\\n'+\\\n",
        "    'RMSE: {} += {}\\n'.format(scores['train_RMSE'].mean(), scores['train_RMSE'].std())+\\\n",
        "    'MAPE: {} += {}\\n'.format(scores['train_MAPE'].mean(), scores['train_MAPE'].std())+\\\n",
        "    'Explained Variance: {} += {}\\n'.format(scores['train_Explained Variance'].mean(), scores['train_Explained Variance'].std())+\\\n",
        "    'R2: {} += {}\\n'.format(scores['train_R2'].mean(), scores['train_R2'].std())\n",
        "    )\n",
        "\n",
        "    print('Test scores: \\n\\n'+\\\n",
        "    'RMSE: {} += {}\\n'.format(scores['test_RMSE'].mean(), scores['test_RMSE'].std())+\\\n",
        "    'MAPE: {} += {}\\n'.format(scores['test_MAPE'].mean(), scores['test_MAPE'].std())+\\\n",
        "    'Explained Variance: {} += {}\\n'.format(scores['test_Explained Variance'].mean(), scores['test_Explained Variance'].std())+\\\n",
        "    'R2: {} += {}\\n'.format(scores['test_R2'].mean(), scores['test_R2'].std())\n",
        "    )\n",
        "\n",
        "    plot_model = LinearRegression();\n",
        "    plot_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    print('Plot model')\n",
        "\n",
        "    yhat = plot_model.predict(X_test)\n",
        "\n",
        "    # evaluate metrics\n",
        "    rmse = mean_squared_error(y_test, yhat)**0.5\n",
        "    mape = mean_absolute_percentage_error(y_test, yhat)\n",
        "    expl_var = explained_variance_score(y_test, yhat)\n",
        "    r2 = r2_score(y_test, yhat)\n",
        "\n",
        "    print('RMSE: %.3f' % rmse)\n",
        "    print('MAPE: %.3f percent' % mape)\n",
        "    print('Explained Variance: %.3f' % expl_var)\n",
        "    print('R2: %.3f' % r2)\n",
        "    print('')\n",
        "    # foobar = pd.DataFrame(plot_model.predict(X_test))\n",
        "    # foobar.index = X_test.index\n",
        "\n",
        "    foobar = pd.DataFrame(plot_model.predict(X))\n",
        "    foobar.index = X.index\n",
        "\n",
        "    # ax=sns.lineplot(data=foobar.resample('W').mean(), x=foobar.resample('W').mean().index, y=0, label='predicted')\n",
        "    # ax=sns.lineplot(data=y.resample('W').mean(), label='actual', ax=ax)\n",
        "    # ax.set_title(name)\n",
        "    # ax.set_xlabel('Year')\n",
        "    # ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    # plt.show()\n",
        "\n",
        "    # combined_data_with_nans_daily['bin_kwh']['2013-02':'2016-01-31'].plot()\n",
        "    # sns.lineplot( data=foobar, x=foobar.index, y=0, label='predicted')\n",
        "\n",
        "    axs[int(i/3),i%3]=sns.lineplot(ax=axs[int(i/3),i%3], data=foobar.resample('W').sum(), x=foobar.resample('W').sum().index, y=0, label='predicted')\n",
        "    axs[int(i/3),i%3]=sns.lineplot(data=y.resample('W').sum(), label='actual', ax=axs[int(i/3),i%3])\n",
        "    axs[int(i/3),i%3].set_title(name)\n",
        "    axs[int(i/3),i%3].set_xlabel('')\n",
        "    axs[int(i/3),i%3].set_ylabel('')\n",
        "    axs[int(i/3),i%3].set(ylim=(-1000,45000))\n",
        "    axs[int(i/3),i%3].set_xticks(pd.date_range('2013-01','2016-01-31', freq='AS'))\n",
        "\n",
        "    i=i+1\n",
        "axs[0,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[1,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[1,0].set_xlabel('Year')\n",
        "axs[1,1].set_xlabel('Year')\n",
        "axs[1,2].set_xlabel('Year')\n",
        "axs[-1,-1].axis('off')\n",
        "# ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "    #\n",
        "    # X_train.shape\n",
        "    # X_test.shape\n",
        "    #\n",
        "    # X_train.columns\n",
        "    #\n",
        "    # plot_model.coef_\n",
        "\n",
        "    # ax=foobar.resample('W').mean().plot()\n",
        "    # y_test.resample('W').mean().plot(ax=ax)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(2, 3, figsize=(25,8))\n",
        "i=0\n",
        "for dataset in using_datas:\n",
        "\n",
        "    name, X, y, X_train, X_test, y_train, y_test = dataset\n",
        "\n",
        "\n",
        "\n",
        "    # evaluate the model\n",
        "    scoring = {'RMSE': make_scorer( lambda y_true, y_pred: mean_squared_error(y_true, y_pred)**0.5 ),\n",
        "               'MAPE': make_scorer( mean_absolute_percentage_error ),\n",
        "               'Explained Variance': make_scorer( explained_variance_score ),\n",
        "               'R2': make_scorer( r2_score )}\n",
        "\n",
        "    foo = GridSearchCV(estimator=Lasso(), scoring=make_scorer(r2_score), param_grid={'alpha': np.arange(0,2,0.05)})\n",
        "    foo.fit(X_train,y_train);\n",
        "    alp = foo.best_params_['alpha']\n",
        "    model = Lasso(alpha=alp)\n",
        "\n",
        "    print( f'{name}, lambda(alpha)={alp}' )\n",
        "\n",
        "    shuffler = ShuffleSplit(n_splits=10, test_size=0.33, random_state=1)\n",
        "    scores = cross_validate(model, X, y, scoring=scoring,\n",
        "                             cv=shuffler, return_train_score=True)\n",
        "\n",
        "\n",
        "    print('Train scores: \\n\\n'+\\\n",
        "    'RMSE: {} += {}\\n'.format(scores['train_RMSE'].mean(), scores['train_RMSE'].std())+\\\n",
        "    'MAPE: {} += {}\\n'.format(scores['train_MAPE'].mean(), scores['train_MAPE'].std())+\\\n",
        "    'Explained Variance: {} += {}\\n'.format(scores['train_Explained Variance'].mean(), scores['train_Explained Variance'].std())+\\\n",
        "    'R2: {} += {}\\n'.format(scores['train_R2'].mean(), scores['train_R2'].std())\n",
        "    )\n",
        "\n",
        "    print('Test scores: \\n\\n'+\\\n",
        "    'RMSE: {} += {}\\n'.format(scores['test_RMSE'].mean(), scores['test_RMSE'].std())+\\\n",
        "    'MAPE: {} += {}\\n'.format(scores['test_MAPE'].mean(), scores['test_MAPE'].std())+\\\n",
        "    'Explained Variance: {} += {}\\n'.format(scores['test_Explained Variance'].mean(), scores['test_Explained Variance'].std())+\\\n",
        "    'R2: {} += {}\\n'.format(scores['test_R2'].mean(), scores['test_R2'].std())\n",
        "    )\n",
        "\n",
        "    plot_model = Lasso(alpha=alp);\n",
        "    plot_model.fit(X_train, y_train)\n",
        "    # yhat\n",
        "    # y_test.var()\n",
        "    # 1 - (y_test-yhat).var()/y_test.var()\n",
        "    # 1 - (y_test - np.zeros_like(yhat) + y_test.mean()).var() / y_test.var()\n",
        "    print('Plot model')\n",
        "\n",
        "    yhat = plot_model.predict(X_test)\n",
        "\n",
        "    # evaluate metrics\n",
        "    rmse = mean_squared_error(y_test, yhat)**0.5\n",
        "    mape = mean_absolute_percentage_error(y_test, yhat)\n",
        "    expl_var = explained_variance_score(y_test, yhat)\n",
        "    r2 = r2_score(y_test, yhat)\n",
        "\n",
        "    print('RMSE: %.3f' % rmse)\n",
        "    print('MAPE: %.3f percent' % mape)\n",
        "    print('Explained Variance: %.3f' % expl_var)\n",
        "    print('R2: %.3f' % r2)\n",
        "\n",
        "    # foobar = pd.DataFrame(plot_model.predict(X_test))\n",
        "    # foobar.index = X_test.index\n",
        "\n",
        "    foobar = pd.DataFrame(plot_model.predict(X))\n",
        "    foobar.index = X.index\n",
        "\n",
        "    # ax=sns.lineplot(data=foobar.resample('W').mean(), x=foobar.resample('W').mean().index, y=0, label='predicted')\n",
        "    # ax=sns.lineplot(data=y.resample('W').mean(), label='actual', ax=ax)\n",
        "    # ax.set_title(name)\n",
        "    # ax.set_xlabel('Year')\n",
        "    # ax.set_ylabel('Electricity Consumption (kWh)')\n",
        "    # plt.show()\n",
        "\n",
        "    axs[int(i/3),i%3]=sns.lineplot(ax=axs[int(i/3),i%3], data=foobar.resample('W').sum(), x=foobar.resample('W').sum().index, y=0, label='predicted')\n",
        "    axs[int(i/3),i%3]=sns.lineplot(data=y.resample('W').sum(), label='actual', ax=axs[int(i/3),i%3])\n",
        "    axs[int(i/3),i%3].set_title(name)\n",
        "    axs[int(i/3),i%3].set_xlabel('')\n",
        "    axs[int(i/3),i%3].set_ylabel('')\n",
        "    axs[int(i/3),i%3].set(ylim=(-1000,45000))\n",
        "    axs[int(i/3),i%3].set_xticks(pd.date_range('2013-01','2016-01-31', freq='AS'))\n",
        "\n",
        "    i=i+1\n",
        "axs[0,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[1,0].set_ylabel('Electricity Consumption (kWh)')\n",
        "axs[1,0].set_xlabel('Year')\n",
        "axs[1,1].set_xlabel('Year')\n",
        "axs[1,2].set_xlabel('Year')\n",
        "axs[-1,-1].axis('off')\n",
        "# ax.set_xticklabels(['Jan','Feb',\"Mar\",'Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "# plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "X, y = new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 1 ][hourly_features].dropna().iloc[:,:-1], new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 1 ][hourly_features].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[0]=sns.barplot(ax=axs[0], x=X.columns, y=plot_model.coef_)\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=30, ha=\"right\")\n",
        "axs[0].set(ylim=(-60,50))\n",
        "axs[0].set_title('Weekend data')\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 0 ][hourly_features].dropna().iloc[:,:-1], new_combined_data_with_nans['2013-02':'2016-01-31'][ new_combined_data_with_nans['WEEKEND'] == 0 ][hourly_features].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[1]=sns.barplot(ax=axs[1], x=X.columns, y=plot_model.coef_)\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=30, ha=\"right\")\n",
        "axs[1].set_title('Weekday data')\n",
        "axs[1].set(ylim=(-60,50))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[0]=sns.barplot(ax=axs[0], x=X.columns, y=plot_model.coef_)\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=33, ha=\"right\")\n",
        "axs[0].set_yscale('symlog')\n",
        "axs[0].set(ylim=(-10e4,10e4))\n",
        "axs[0].set_title('Hourly data')\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[1]=sns.barplot(ax=axs[1], x=X.columns, y=plot_model.coef_)\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=33, ha=\"right\")\n",
        "axs[1].set_yscale('symlog')\n",
        "axs[1].set(ylim=(-10e4,10e4))\n",
        "axs[1].set_title('Daily data')\n",
        "\n",
        "X, y = new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[2]=sns.barplot(ax=axs[2], x=X.columns, y=plot_model.coef_)\n",
        "axs[2].set_xticklabels(axs[2].get_xticklabels(), rotation=33, ha=\"right\")\n",
        "axs[2].set_yscale('symlog')\n",
        "axs[2].set(ylim=(-10e4,10e4))\n",
        "axs[2].set_title('Weekly data')\n",
        "new_combined_data_with_nans.dropna()['NO_WIND'].value_counts()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    X_train.columns\n",
        "    X_train.columns[plot_model.coef_ != 0]\n",
        "    plot_model.coef_[plot_model.coef_.argsort()]\n",
        "\n",
        "\n",
        "\n",
        "    X_train.columns[plot_model.coef_.argsort()]\n",
        "    weekday_features\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, figsize=(20,5))\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "foobar = pd.DataFrame(plot_model.predict(X))\n",
        "foobar.index = X.index\n",
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "axs[0]=sns.lineplot(ax=axs[0], data=foobar['2014-2'], x=foobar['2014-2'].index, y=0, label='predicted')\n",
        "axs[0]=sns.lineplot(data=y['2014-2'], label='actual', ax=axs[0])\n",
        "axs[0].set_title('Hourly data')\n",
        "axs[0].set_xlabel('')\n",
        "axs[0].set_ylabel('')\n",
        "axs[0].set(ylim=(0,325))\n",
        "axs[0].set_xticks(pd.date_range('2014-02','2014-3', freq='MS'))\n",
        "\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "foobar = pd.DataFrame(plot_model.predict(X))\n",
        "foobar.index = X.index\n",
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "axs[1]=sns.lineplot(ax=axs[1], data=foobar['2014-2'], x=foobar['2014-2'].index, y=0, label='predicted')\n",
        "axs[1]=sns.lineplot(data=y['2014-2'], label='actual', ax=axs[1])\n",
        "axs[1].set_title('Daily data')\n",
        "axs[1].set_xlabel('')\n",
        "axs[1].set_ylabel('')\n",
        "axs[1].set(ylim=(0,5600))\n",
        "axs[1].set_xticks(pd.date_range('2014-02','2014-3', freq='MS'))\n",
        "\n",
        "X, y = new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_weekly[weekly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "foobar = pd.DataFrame(plot_model.predict(X))\n",
        "foobar.index = X.index\n",
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "axs[2]=sns.lineplot(ax=axs[2], data=foobar['2014-2'], x=foobar['2014-2'].index, y=0, label='predicted')\n",
        "axs[2]=sns.lineplot(data=y['2014-2'], label='actual', ax=axs[2])\n",
        "axs[2].set_title('Weekly data')\n",
        "axs[2].set_xlabel('')\n",
        "axs[2].set_ylabel('')\n",
        "axs[2].set(ylim=(0,37000))\n",
        "axs[2].set_xticks(pd.date_range('2014-02','2014-3', freq='MS'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().join( data_ups_combine_converted_filtered['Other'] )['Other']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "foobar = pd.DataFrame(plot_model.predict(X))\n",
        "foobar.index = X.index\n",
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "axs[0]=sns.lineplot(ax=axs[0], data=foobar['2014-2'], x=foobar['2014-2'].index, y=0, label='predicted')\n",
        "axs[0]=sns.lineplot(data=y['2014-2'], label='actual', ax=axs[0])\n",
        "axs[0].set_title('Hourly data with UPS and Forum consumption removed')\n",
        "axs[0].set_xlabel('')\n",
        "axs[0].set_ylabel('')\n",
        "axs[0].set(ylim=(0,325))\n",
        "axs[0].set_xticks(pd.date_range('2014-02','2014-3', freq='MS'))\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans[hourly_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "# X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().join( data_ups_combine_converted_filtered['Other'].resample('D').sum() )['Other']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "foobar = pd.DataFrame(plot_model.predict(X))\n",
        "foobar.index = X.index\n",
        "\n",
        "# plt.figure(figsize=(15,8))\n",
        "axs[1]=sns.lineplot(ax=axs[1], data=foobar['2014-2'], x=foobar['2014-2'].index, y=0, label='predicted')\n",
        "axs[1]=sns.lineplot(data=y['2014-2'], label='actual', ax=axs[1])\n",
        "axs[1].set_title('Hourly data')\n",
        "axs[1].set_xlabel('')\n",
        "axs[1].set_ylabel('')\n",
        "axs[1].set(ylim=(0,325))\n",
        "axs[1].set_xticks(pd.date_range('2014-02','2014-3', freq='MS'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fig, axs = plt.subplots(1, 2, figsize=(20,5))\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().join( data_ups_combine_converted_filtered['Other'].resample('D').sum() )['Other']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[0]=sns.barplot(ax=axs[0], x=X.columns, y=plot_model.coef_)\n",
        "axs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=30, ha=\"right\")\n",
        "axs[0].set(ylim=(-2000,1500))\n",
        "axs[0].set_title('Hourly data with UPS and Forum consumption removed')\n",
        "\n",
        "\n",
        "X, y = new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna().drop('bin_kwh', axis=1), new_combined_data_with_nans_daily[daily_features]['2013-02':'2016-01-31'].dropna()['bin_kwh']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
        "\n",
        "plot_model = LinearRegression();\n",
        "plot_model.fit(X, y)\n",
        "X.columns\n",
        "plot_model.coef_\n",
        "plt.figure(figsize=(15,8))\n",
        "axs[1]=sns.barplot(ax=axs[1], x=X.columns, y=plot_model.coef_)\n",
        "axs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=30, ha=\"right\")\n",
        "axs[1].set_title('Hourly data')\n",
        "axs[1].set(ylim=(-2000,1500))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# from tsfresh import extract_relevant_features\n",
        "#\n",
        "# features_filtered_direct = extract_relevant_features(X.reset_index(), y,\n",
        "#                                                      column_id='OB_TIME')\n",
        "#\n",
        "#\n",
        "# features_filtered_direct\n",
        "#\n",
        "#\n",
        "# my_model = LinearRegression()\n",
        "# my_model.fit(features_filtered_direct, y)\n",
        "#\n",
        "#\n",
        "# # evaluate the model\n",
        "# yhat = my_model.predict(features_filtered_direct)\n",
        "# # evaluate predictions\n",
        "# rmse = mean_squared_error(y, yhat)**0.5\n",
        "# print('RMSE: %.3f' % rmse)\n",
        "#\n",
        "# ax=sns.lineplot(x=features_filtered_direct.index, y=my_model.predict(features_filtered_direct))\n",
        "#\n",
        "# y.plot(ax=ax)\n",
        "#\n",
        "# "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# "
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# features_filtered_direct_2 = extract_relevant_features(new_combined_data_with_nans[ [col for col in new_combined_data_with_nans.columns if col != 'bin_kwh' ] ].dropna().reset_index(), new_combined_data_with_nans.dropna()['bin_kwh'],\n",
        "#                                                      column_id='OB_TIME')\n",
        "#\n",
        "#\n",
        "# features_filtered_direct_2\n",
        "#\n",
        "#\n",
        "# my_model = LinearRegression()\n",
        "# my_model.fit(features_filtered_direct, y)\n",
        "#\n",
        "#\n",
        "# # evaluate the model\n",
        "# yhat = my_model.predict(features_filtered_direct)\n",
        "# # evaluate predictions\n",
        "# rmse = mean_squared_error(y, yhat)**0.5\n",
        "# print('RMSE: %.3f' % rmse)\n",
        "#\n",
        "# ax=sns.lineplot(x=features_filtered_direct.index, y=my_model.predict(features_filtered_direct))\n",
        "#\n",
        "# y.plot(ax=ax)\n",
        "#\n",
        "#\n",
        "# # minus UPS;\n",
        "# # monthly;"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/lautinyeung/miniconda3/envs/r/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}